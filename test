from pyspark import SparkConf, SparkContext
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator

def init():
    conf = SparkConf().setAppName("Tarea3").setMaster("local")
    return SparkContext(conf=conf)

def load_dataset(spark):
    rdd = spark.sparkContext.textFile(
        "data/FullData.csv").map(lambda linea: linea.split(","))
    rdd_data = rdd.map(lambda sample: [
        sample[0], sample[9], sample[10],
        sample[11], sample[15], sample[18], sample[19], sample[20],
        sample[21], sample[22], sample[23], sample[24], sample[25],
        sample[26], sample[27], sample[28], sample[29], sample[30],
        sample[31], sample[32], sample[33], sample[34], sample[35],
        sample[36], sample[37], sample[38], sample[39], sample[40],
        sample[41], sample[42], sample[43], sample[44], sample[45],
        sample[46], sample[47]])
    headers = ["NAME", "RATING", "HEIGHT", "WEIGHT",
        "POSITION", "STAT1", "STAT2", "STAT3", "STAT4", "STAT5",
        "STAT6", "STAT7", "STAT8", "STAT9", "STAT10", "STAT11", "STAT12",
        "STAT13", "STAT14", "STAT15", "STAT16", "STAT17", "STAT18", "STAT19",
        "STAT20", "STAT21", "STAT22", "STAT23", "STAT24", "STAT25", "STAT26",
        "STAT27", "STAT28", "STAT29", "STAT30"]
    return spark.createDataFrame(rdd_data, headers)

def prepare_dataset(data):
    train, test = data.randomSplit(
        [0.7, 0.3], seed=12345
    )
    train.show()
    headers_feature = ["RATING", "HEIGHT", "WEIGHT",
        "POSITION", "STAT1", "STAT2", "STAT3", "STAT4", "STAT5",
        "STAT6", "STAT7", "STAT8", "STAT9", "STAT10", "STAT11", "STAT12",
        "STAT13", "STAT14", "STAT15", "STAT16", "STAT17", "STAT18", "STAT19",
        "STAT20", "STAT21", "STAT22", "STAT23", "STAT24", "STAT25", "STAT26",
        "STAT27", "STAT28", "STAT29", "STAT30"]
    header_output = "features"

    assembler = VectorAssembler(
        inputCols=headers_feature,
        outputCol=header_output)
    train_data = assembler.transform(train).select("features", "CLASS")
    test_data = assembler.transform(test).select("features", "CLASS")

    return train_data,test_data

def main():
    sc = init()
    spark = SparkSession(sc)
    data = load_dataset(spark)

    train_data, test_data = prepare_dataset(data)
    #train_data.show()
    #test_data.show()

    lr = LogisticRegression(
        maxIter=500, regParam=0.3, elasticNetParam=0.8,
        labelCol='CLASS', family='binomial')

    lr_model = lr.fit(train_data)

    print("Coeficients: " + str(lr_model.coefficients))
    print("Intercept: " + str(lr_model.intercept))

    data_to_validate = lr_model.transform(test_data)

    evaluator1 = BinaryClassificationEvaluator(
        labelCol='CLASS', metricName='offensive',
        rawPredictionCol='rawPrediction'
    )
    print("{}:{}".format(
        "offensive",evaluator1.evaluate(data_to_validate)))

    evaluator2 = BinaryClassificationEvaluator(
        labelCol='CLASS', metricName='defensive',
        rawPredictionCol='rawPrediction'
    )
    print("{}:{}".format(
        "defensive",evaluator2.evaluate(data_to_validate)))

if __name__ == '__main__':
    main()
